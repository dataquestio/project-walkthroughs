{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ab8d51d6-7670-4cfb-87d1-f1c30fa2666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"mvps.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "               Player Pos  Age   Tm   G  GS    MP   FG   FGA    FG%  ...  TOV  \\\n0          A.C. Green  PF   27  LAL  82  21  26.4  3.1   6.6  0.476  ...  1.2   \n1         Byron Scott  SG   29  LAL  82  82  32.1  6.1  12.8  0.477  ...  1.0   \n2      Elden Campbell  PF   22  LAL  52   0   7.3  1.1   2.4  0.455  ...  0.3   \n3       Irving Thomas  PF   25  LAL  26   0   4.2  0.7   1.9  0.340  ...  0.5   \n4        James Worthy  SF   29  LAL  78  74  38.6  9.2  18.7  0.492  ...  1.6   \n...               ...  ..  ...  ...  ..  ..   ...  ...   ...    ...  ...  ...   \n14087   Spencer Hawes  PF   28  MIL  54   1  14.8  2.5   5.1  0.484  ...  0.9   \n14088     Steve Novak  PF   33  MIL   8   0   2.8  0.3   0.9  0.286  ...  0.0   \n14089  Terrence Jones  PF   25  MIL  54  12  23.5  4.3   9.1  0.470  ...  0.9   \n14090      Thon Maker   C   19  MIL  57  34   9.9  1.5   3.2  0.459  ...  0.3   \n14091      Tony Snell  SG   25  MIL  80  80  29.2  3.1   6.8  0.455  ...  0.7   \n\n        PF   PTS  Year   W   L   W/L%   GB   SRS  MVP Votes  \n0      1.4   9.1  1991  58  24  0.707  5.0  6.73        0.0  \n1      1.8  14.5  1991  58  24  0.707  5.0  6.73        0.0  \n2      1.4   2.8  1991  58  24  0.707  5.0  6.73        0.0  \n3      0.9   1.8  1991  58  24  0.707  5.0  6.73        0.0  \n4      1.5  21.4  1991  58  24  0.707  5.0  6.73        0.0  \n...    ...   ...   ...  ..  ..    ...  ...   ...        ...  \n14087  1.4   6.2  2017  42  40  0.512  9.0 -0.45        0.0  \n14088  0.1   0.6  2017  42  40  0.512  9.0 -0.45        0.0  \n14089  1.2  10.8  2017  42  40  0.512  9.0 -0.45        0.0  \n14090  1.5   4.0  2017  42  40  0.512  9.0 -0.45        0.0  \n14091  1.6   8.5  2017  42  40  0.512  9.0 -0.45        0.0  \n\n[14092 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Player</th>\n      <th>Pos</th>\n      <th>Age</th>\n      <th>Tm</th>\n      <th>G</th>\n      <th>GS</th>\n      <th>MP</th>\n      <th>FG</th>\n      <th>FGA</th>\n      <th>FG%</th>\n      <th>...</th>\n      <th>TOV</th>\n      <th>PF</th>\n      <th>PTS</th>\n      <th>Year</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>SRS</th>\n      <th>MVP Votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A.C. Green</td>\n      <td>PF</td>\n      <td>27</td>\n      <td>LAL</td>\n      <td>82</td>\n      <td>21</td>\n      <td>26.4</td>\n      <td>3.1</td>\n      <td>6.6</td>\n      <td>0.476</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>1.4</td>\n      <td>9.1</td>\n      <td>1991</td>\n      <td>58</td>\n      <td>24</td>\n      <td>0.707</td>\n      <td>5.0</td>\n      <td>6.73</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Byron Scott</td>\n      <td>SG</td>\n      <td>29</td>\n      <td>LAL</td>\n      <td>82</td>\n      <td>82</td>\n      <td>32.1</td>\n      <td>6.1</td>\n      <td>12.8</td>\n      <td>0.477</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.8</td>\n      <td>14.5</td>\n      <td>1991</td>\n      <td>58</td>\n      <td>24</td>\n      <td>0.707</td>\n      <td>5.0</td>\n      <td>6.73</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Elden Campbell</td>\n      <td>PF</td>\n      <td>22</td>\n      <td>LAL</td>\n      <td>52</td>\n      <td>0</td>\n      <td>7.3</td>\n      <td>1.1</td>\n      <td>2.4</td>\n      <td>0.455</td>\n      <td>...</td>\n      <td>0.3</td>\n      <td>1.4</td>\n      <td>2.8</td>\n      <td>1991</td>\n      <td>58</td>\n      <td>24</td>\n      <td>0.707</td>\n      <td>5.0</td>\n      <td>6.73</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Irving Thomas</td>\n      <td>PF</td>\n      <td>25</td>\n      <td>LAL</td>\n      <td>26</td>\n      <td>0</td>\n      <td>4.2</td>\n      <td>0.7</td>\n      <td>1.9</td>\n      <td>0.340</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>1.8</td>\n      <td>1991</td>\n      <td>58</td>\n      <td>24</td>\n      <td>0.707</td>\n      <td>5.0</td>\n      <td>6.73</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>James Worthy</td>\n      <td>SF</td>\n      <td>29</td>\n      <td>LAL</td>\n      <td>78</td>\n      <td>74</td>\n      <td>38.6</td>\n      <td>9.2</td>\n      <td>18.7</td>\n      <td>0.492</td>\n      <td>...</td>\n      <td>1.6</td>\n      <td>1.5</td>\n      <td>21.4</td>\n      <td>1991</td>\n      <td>58</td>\n      <td>24</td>\n      <td>0.707</td>\n      <td>5.0</td>\n      <td>6.73</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14087</th>\n      <td>Spencer Hawes</td>\n      <td>PF</td>\n      <td>28</td>\n      <td>MIL</td>\n      <td>54</td>\n      <td>1</td>\n      <td>14.8</td>\n      <td>2.5</td>\n      <td>5.1</td>\n      <td>0.484</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.4</td>\n      <td>6.2</td>\n      <td>2017</td>\n      <td>42</td>\n      <td>40</td>\n      <td>0.512</td>\n      <td>9.0</td>\n      <td>-0.45</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14088</th>\n      <td>Steve Novak</td>\n      <td>PF</td>\n      <td>33</td>\n      <td>MIL</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2.8</td>\n      <td>0.3</td>\n      <td>0.9</td>\n      <td>0.286</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.6</td>\n      <td>2017</td>\n      <td>42</td>\n      <td>40</td>\n      <td>0.512</td>\n      <td>9.0</td>\n      <td>-0.45</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14089</th>\n      <td>Terrence Jones</td>\n      <td>PF</td>\n      <td>25</td>\n      <td>MIL</td>\n      <td>54</td>\n      <td>12</td>\n      <td>23.5</td>\n      <td>4.3</td>\n      <td>9.1</td>\n      <td>0.470</td>\n      <td>...</td>\n      <td>0.9</td>\n      <td>1.2</td>\n      <td>10.8</td>\n      <td>2017</td>\n      <td>42</td>\n      <td>40</td>\n      <td>0.512</td>\n      <td>9.0</td>\n      <td>-0.45</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14090</th>\n      <td>Thon Maker</td>\n      <td>C</td>\n      <td>19</td>\n      <td>MIL</td>\n      <td>57</td>\n      <td>34</td>\n      <td>9.9</td>\n      <td>1.5</td>\n      <td>3.2</td>\n      <td>0.459</td>\n      <td>...</td>\n      <td>0.3</td>\n      <td>1.5</td>\n      <td>4.0</td>\n      <td>2017</td>\n      <td>42</td>\n      <td>40</td>\n      <td>0.512</td>\n      <td>9.0</td>\n      <td>-0.45</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14091</th>\n      <td>Tony Snell</td>\n      <td>SG</td>\n      <td>25</td>\n      <td>MIL</td>\n      <td>80</td>\n      <td>80</td>\n      <td>29.2</td>\n      <td>3.1</td>\n      <td>6.8</td>\n      <td>0.455</td>\n      <td>...</td>\n      <td>0.7</td>\n      <td>1.6</td>\n      <td>8.5</td>\n      <td>2017</td>\n      <td>42</td>\n      <td>40</td>\n      <td>0.512</td>\n      <td>9.0</td>\n      <td>-0.45</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14092 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f3791a81-d488-4c7c-909b-8105c6b60587",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTORS = [p for p in data.columns if p not in [\"Player\", \"Tm\", \"Pos\", \"MVP Votes\", \"Year\"]]\n",
    "TARGET = \"MVP Votes\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[PREDICTORS] = scaler.fit_transform(data[PREDICTORS])\n",
    "\n",
    "split_data = np.split(data, [int(.7*len(data)), int(.85*len(data))])\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = [[d[PREDICTORS].to_numpy(), d[[TARGET]].to_numpy()] for d in split_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "31"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PREDICTORS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fc393270-36ea-4516-9bc7-a7ce51c59d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    return np.mean((actual-predicted)**2)\n",
    "\n",
    "def mse_grad(actual, predicted):\n",
    "    return (predicted - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b1547940-59a1-40b6-8b7f-1ca15e414ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layers(inputs):\n",
    "    layers = []\n",
    "    for i in range(1, len(inputs)):\n",
    "        layers.append([\n",
    "            np.random.rand(inputs[i-1], inputs[i]) / 5 - .1,\n",
    "            np.ones((1,inputs[i]))\n",
    "        ])\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f2a780eb-d517-4489-b19b-f6e319c11ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch, layers):\n",
    "    hidden = [batch.copy()]\n",
    "    for i in range(len(layers)):\n",
    "        batch = np.matmul(batch, layers[i][0]) + layers[i][1]\n",
    "        hidden.append(batch.copy())\n",
    "        if i < len(layers) - 1:\n",
    "            batch = np.maximum(batch, 0)\n",
    "        \n",
    "    return layers, batch, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9b48ba67-863e-49ab-97f1-85322a28c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(layers, hidden, grad, lr):\n",
    "    for i in range(len(layers)-1, -1, -1):\n",
    "        print(f\"Layer {i}\")\n",
    "        if i != len(layers) - 1:\n",
    "            grad = np.multiply(grad, np.heaviside(hidden[i+1], 1))\n",
    "        \n",
    "        grad = grad.T\n",
    "        w_grad = np.matmul(grad, hidden[i]).T\n",
    "        b_grad = grad.T\n",
    "        \n",
    "        layers[i][0] -= (w_grad + layers[i][0] * .01) * lr\n",
    "        layers[i][1] -= b_grad * lr\n",
    "        \n",
    "        grad = np.matmul(layers[i][0], grad).T\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input\n",
    "\n",
    "1,31\n",
    "\n",
    "## Outputs\n",
    "\n",
    "1,25\n",
    "1,25\n",
    "1,10\n",
    "1,1\n",
    "\n",
    "## Weights\n",
    "\n",
    "31,25\n",
    "25,25\n",
    "25,10\n",
    "10,1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c76220dc-15c3-4b46-83af-7d644c47d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train: 4128.774670998684 Valid: 4249.708262993707\n",
      "10 Train: 4117.575207061994 Valid: 4237.858833145232\n",
      "20 Train: 4106.327294795145 Valid: 4225.761806960189\n",
      "30 Train: 4092.155593829098 Valid: 4209.827975231823\n",
      "40 Train: 4013.307422126987 Valid: 4115.69234151883\n",
      "50 Train: 3643.752076622798 Valid: 3710.7376805342255\n",
      "60 Train: 2747.351484633631 Valid: 2762.8483198174517\n",
      "70 Train: 2135.0136452069582 Valid: 2018.1166520829229\n",
      "80 Train: 1897.7670490074024 Valid: 1605.8168320528596\n",
      "90 Train: 1766.3985398259247 Valid: 1403.487528818823\n",
      "100 Train: 1686.8170039463964 Valid: 1355.6076306771417\n",
      "110 Train: 1610.1019969181593 Valid: 1393.9442127672996\n",
      "120 Train: 1564.1540836417548 Valid: 1409.47644696942\n",
      "130 Train: 1513.679212457258 Valid: 1359.8473807505782\n",
      "140 Train: 1469.0184524561232 Valid: 1341.8936802452797\n",
      "150 Train: 1425.6213487045584 Valid: 1285.1308786375898\n"
     ]
    }
   ],
   "source": [
    "layer_conf = [len(PREDICTORS),25,25,10,1]\n",
    "lr = 2e-3\n",
    "epochs=150\n",
    "\n",
    "layers = init_layers(layer_conf)\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, row in enumerate(train_x):\n",
    "        row = row.copy().reshape((1,train_x.shape[1]))\n",
    "        layers, pred, hidden = forward(row, layers)\n",
    "\n",
    "        loss = mse_grad(train_y[i,0], pred[0,0])\n",
    "        epoch_loss += loss ** 2\n",
    "\n",
    "        layers = backward(layers, hidden, np.array(loss).reshape(1,1), lr/train_x.shape[0])\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        _, valid_preds, _ = forward(valid_x, layers)\n",
    "        \n",
    "        print(f\"{epoch} Train: {epoch_loss/train_x.shape[0]} Valid: {mse(valid_preds,valid_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "483f40c0-919f-4f43-b4f9-092dc904c84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2634.684486894264"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, test_preds, _ = forward(test_x, layers)\n",
    "mse(test_preds,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "947f193c-92d8-4c2b-a8a9-37e6cbc53aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      index              Player Pos       Age   Tm         G        GS  \\\n1805  13783       Kevin Garnett  PF  0.058795  MIN  1.171440  1.939334   \n996   12974        LeBron James  PF  0.294511  MIA  0.932406  1.732928   \n202   12180        Derrick Rose  PG -1.119785  CHI  1.131601  1.904933   \n1044  13022        LeBron James  SF  0.058795  MIA  0.374662  1.251312   \n356   12334          Tim Duncan  PF -0.176921  SAS  1.131601  1.904933   \n...     ...                 ...  ..       ...  ...       ...       ...   \n714   12692       DeSagana Diop   C -1.119785  CLE  0.135628 -0.778353   \n713   12691       Dajuan Wagner  SG -1.591217  CLE -0.342439 -0.743952   \n712   12690       Carlos Boozer  PF -1.119785  CLE  0.892568  1.698526   \n711   12689  Zydrunas Ilgauskas   C  0.058795  CLE  1.131601  1.904933   \n2113  14091          Tony Snell  SG -0.412637  MIL  1.091762  1.870532   \n\n            MP        FG       FGA  ...        PF       PTS  Year         W  \\\n1805  1.880308  3.041269  2.741043  ...  0.751097  2.662314  2004  1.428952   \n996   1.732020  3.177385  2.352990  ... -0.577577  3.096417  2013  2.049151   \n202   1.682591  2.587551  2.762601  ... -0.215211  2.795884  2011  1.739052   \n1044  1.692477  3.132013  2.590133  ... -0.456789  3.146506  2012  0.498653   \n356   1.870422  2.587551  2.223640  ...  1.234252  2.512047  2003  1.584002   \n...        ...       ...       ...  ...       ...       ...   ...       ...   \n714  -0.729553 -0.951449 -0.923894  ...  0.267943 -0.994172  2004 -0.354121   \n713  -0.423092 -0.270872  0.024678  ...  0.147154 -0.292928  2004 -0.354121   \n712   1.405788  1.453256  1.102600  ...  0.992675  1.209737  2004 -0.354121   \n711   0.951039  1.362513  1.512211  ...  1.838195  1.493574  2003 -1.749570   \n2113  0.871952  0.001359 -0.018439  ... -0.336000  0.040998  2017  0.188553   \n\n             L      W/L%        GB       SRS  Pts Won  Pred Pts Won  \n1805 -1.250866  1.352002 -1.191189  1.305799   1219.0    454.762606  \n996  -1.873114  1.981822 -1.191189  1.561916   1207.0    899.846397  \n202  -1.561990  1.666912 -1.191189  1.452464   1182.0    501.325824  \n1044 -1.561990  1.287735 -1.191189  1.275153   1074.0    536.076789  \n356  -1.406428  1.512671 -1.191189  1.259830    962.0    450.183500  \n...        ...       ...       ...       ...      ...           ...  \n714   0.538098 -0.447482  0.785303 -0.649002      0.0      0.198213  \n713   0.538098 -0.447482  0.785303 -0.649002      0.0      0.090225  \n712   0.538098 -0.447482  0.785303 -0.649002      0.0     -0.210942  \n711   1.938156 -1.861363  1.317436 -2.076248      0.0     -0.269048  \n2113 -0.006370  0.098790 -0.507018 -0.075477      0.0     -0.004821  \n\n[2114 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Player</th>\n      <th>Pos</th>\n      <th>Age</th>\n      <th>Tm</th>\n      <th>G</th>\n      <th>GS</th>\n      <th>MP</th>\n      <th>FG</th>\n      <th>FGA</th>\n      <th>...</th>\n      <th>PF</th>\n      <th>PTS</th>\n      <th>Year</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n      <th>GB</th>\n      <th>SRS</th>\n      <th>Pts Won</th>\n      <th>Pred Pts Won</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1805</th>\n      <td>13783</td>\n      <td>Kevin Garnett</td>\n      <td>PF</td>\n      <td>0.058795</td>\n      <td>MIN</td>\n      <td>1.171440</td>\n      <td>1.939334</td>\n      <td>1.880308</td>\n      <td>3.041269</td>\n      <td>2.741043</td>\n      <td>...</td>\n      <td>0.751097</td>\n      <td>2.662314</td>\n      <td>2004</td>\n      <td>1.428952</td>\n      <td>-1.250866</td>\n      <td>1.352002</td>\n      <td>-1.191189</td>\n      <td>1.305799</td>\n      <td>1219.0</td>\n      <td>454.762606</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>12974</td>\n      <td>LeBron James</td>\n      <td>PF</td>\n      <td>0.294511</td>\n      <td>MIA</td>\n      <td>0.932406</td>\n      <td>1.732928</td>\n      <td>1.732020</td>\n      <td>3.177385</td>\n      <td>2.352990</td>\n      <td>...</td>\n      <td>-0.577577</td>\n      <td>3.096417</td>\n      <td>2013</td>\n      <td>2.049151</td>\n      <td>-1.873114</td>\n      <td>1.981822</td>\n      <td>-1.191189</td>\n      <td>1.561916</td>\n      <td>1207.0</td>\n      <td>899.846397</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>12180</td>\n      <td>Derrick Rose</td>\n      <td>PG</td>\n      <td>-1.119785</td>\n      <td>CHI</td>\n      <td>1.131601</td>\n      <td>1.904933</td>\n      <td>1.682591</td>\n      <td>2.587551</td>\n      <td>2.762601</td>\n      <td>...</td>\n      <td>-0.215211</td>\n      <td>2.795884</td>\n      <td>2011</td>\n      <td>1.739052</td>\n      <td>-1.561990</td>\n      <td>1.666912</td>\n      <td>-1.191189</td>\n      <td>1.452464</td>\n      <td>1182.0</td>\n      <td>501.325824</td>\n    </tr>\n    <tr>\n      <th>1044</th>\n      <td>13022</td>\n      <td>LeBron James</td>\n      <td>SF</td>\n      <td>0.058795</td>\n      <td>MIA</td>\n      <td>0.374662</td>\n      <td>1.251312</td>\n      <td>1.692477</td>\n      <td>3.132013</td>\n      <td>2.590133</td>\n      <td>...</td>\n      <td>-0.456789</td>\n      <td>3.146506</td>\n      <td>2012</td>\n      <td>0.498653</td>\n      <td>-1.561990</td>\n      <td>1.287735</td>\n      <td>-1.191189</td>\n      <td>1.275153</td>\n      <td>1074.0</td>\n      <td>536.076789</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>12334</td>\n      <td>Tim Duncan</td>\n      <td>PF</td>\n      <td>-0.176921</td>\n      <td>SAS</td>\n      <td>1.131601</td>\n      <td>1.904933</td>\n      <td>1.870422</td>\n      <td>2.587551</td>\n      <td>2.223640</td>\n      <td>...</td>\n      <td>1.234252</td>\n      <td>2.512047</td>\n      <td>2003</td>\n      <td>1.584002</td>\n      <td>-1.406428</td>\n      <td>1.512671</td>\n      <td>-1.191189</td>\n      <td>1.259830</td>\n      <td>962.0</td>\n      <td>450.183500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>12692</td>\n      <td>DeSagana Diop</td>\n      <td>C</td>\n      <td>-1.119785</td>\n      <td>CLE</td>\n      <td>0.135628</td>\n      <td>-0.778353</td>\n      <td>-0.729553</td>\n      <td>-0.951449</td>\n      <td>-0.923894</td>\n      <td>...</td>\n      <td>0.267943</td>\n      <td>-0.994172</td>\n      <td>2004</td>\n      <td>-0.354121</td>\n      <td>0.538098</td>\n      <td>-0.447482</td>\n      <td>0.785303</td>\n      <td>-0.649002</td>\n      <td>0.0</td>\n      <td>0.198213</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>12691</td>\n      <td>Dajuan Wagner</td>\n      <td>SG</td>\n      <td>-1.591217</td>\n      <td>CLE</td>\n      <td>-0.342439</td>\n      <td>-0.743952</td>\n      <td>-0.423092</td>\n      <td>-0.270872</td>\n      <td>0.024678</td>\n      <td>...</td>\n      <td>0.147154</td>\n      <td>-0.292928</td>\n      <td>2004</td>\n      <td>-0.354121</td>\n      <td>0.538098</td>\n      <td>-0.447482</td>\n      <td>0.785303</td>\n      <td>-0.649002</td>\n      <td>0.0</td>\n      <td>0.090225</td>\n    </tr>\n    <tr>\n      <th>712</th>\n      <td>12690</td>\n      <td>Carlos Boozer</td>\n      <td>PF</td>\n      <td>-1.119785</td>\n      <td>CLE</td>\n      <td>0.892568</td>\n      <td>1.698526</td>\n      <td>1.405788</td>\n      <td>1.453256</td>\n      <td>1.102600</td>\n      <td>...</td>\n      <td>0.992675</td>\n      <td>1.209737</td>\n      <td>2004</td>\n      <td>-0.354121</td>\n      <td>0.538098</td>\n      <td>-0.447482</td>\n      <td>0.785303</td>\n      <td>-0.649002</td>\n      <td>0.0</td>\n      <td>-0.210942</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>12689</td>\n      <td>Zydrunas Ilgauskas</td>\n      <td>C</td>\n      <td>0.058795</td>\n      <td>CLE</td>\n      <td>1.131601</td>\n      <td>1.904933</td>\n      <td>0.951039</td>\n      <td>1.362513</td>\n      <td>1.512211</td>\n      <td>...</td>\n      <td>1.838195</td>\n      <td>1.493574</td>\n      <td>2003</td>\n      <td>-1.749570</td>\n      <td>1.938156</td>\n      <td>-1.861363</td>\n      <td>1.317436</td>\n      <td>-2.076248</td>\n      <td>0.0</td>\n      <td>-0.269048</td>\n    </tr>\n    <tr>\n      <th>2113</th>\n      <td>14091</td>\n      <td>Tony Snell</td>\n      <td>SG</td>\n      <td>-0.412637</td>\n      <td>MIL</td>\n      <td>1.091762</td>\n      <td>1.870532</td>\n      <td>0.871952</td>\n      <td>0.001359</td>\n      <td>-0.018439</td>\n      <td>...</td>\n      <td>-0.336000</td>\n      <td>0.040998</td>\n      <td>2017</td>\n      <td>0.188553</td>\n      <td>-0.006370</td>\n      <td>0.098790</td>\n      <td>-0.507018</td>\n      <td>-0.075477</td>\n      <td>0.0</td>\n      <td>-0.004821</td>\n    </tr>\n  </tbody>\n</table>\n<p>2114 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.iloc[-len(test_x):].reset_index()\n",
    "combined = pd.concat([test, pd.DataFrame(test_preds)], axis=1)\n",
    "combined.columns = list(combined.columns[:-1]) + [\"Pred Pts Won\"]\n",
    "combined.sort_values(\"Pts Won\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
